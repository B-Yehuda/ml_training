[Redshift_Data]
# query to fetch data
query = select DISTINCT se_age_days::float
             , country
             , language
             , ccv_30_d::integer
             , ccv_60_d::integer
             , ccv_growth_60_30_d::float
             , most_played_game
             , cnt_streams::integer

             , weekly_streaming_schedule
             , number_of_channels::integer
             , cnt_played_games::integer
             , competing_invites::integer
             , invitations::integer
             , acceptances::integer
             , deployments::integer
             , rejections::integer
             , offer_page_visits::integer
             , invitations_l3m::integer
             , acceptances_l3m::integer
             , deployments_l3m::integer
             , rejections_l3m::integer
             , offer_page_visits_l3m::integer
             , invitations_l6m::integer
             , acceptances_l6m::integer
             , deployments_l6m::integer
             , rejections_l6m::integer
             , offer_page_visits_l6m::integer
             , hours_streamed::float
             , hours_watched::integer
             , total_chatters::integer
             , is_tipping_panel::integer
             , is_bot_command_usage::integer
             , cnt_bot_command_usage::integer
             , cnt_days_bot_command_usage::integer
             , is_overlay::integer
             , cnt_days_overlay::integer
             , is_website_visit::integer
             , cnt_website_visit::integer
             , cnt_days_website_visit::integer
             , is_se_live::integer
             , cnt_se_live::integer
             , cnt_days_se_live::integer
             , is_alert_box_fired::integer
             , cnt_alert_box_fired::integer
             , cnt_days_alert_box_fired::integer
             , is_sesp_page_visit::integer
             , cnt_sesp_page_visits::integer
             , cnt_days_sesp_page_visits::integer
             , is_open_stream_report::integer
             , cnt_open_stream_report::integer
             , cnt_days_open_stream_report::integer
             , campaigns_revenue::integer
             , campaigns_revenue_l3m::integer
             , campaigns_revenue_l6m::integer
             , manual_campaigns_revenue::integer
             , manual_campaigns_revenue_l3m::integer
             , manual_campaigns_revenue_l6m::integer
             , sesp_campaigns_revenue::integer
             , sesp_campaigns_revenue_l3m::integer
             , sesp_campaigns_revenue_l6m::integer
             , tips::integer
             , tips_revenue::float
             , on_screen_cheers::integer
             , on_screen_cheers_revenue::float
             , on_screen_subs::integer
             , on_screen_subs_revenue::float

             , raid_deployment_number::integer
             , num_of_successful_previous_deployments::integer
             , days_between_last_stream_and_raid_deployment::float

             -- Not included in bi_db.v_daily_features
             , application_id
             , tutorials_d7::integer
             -- , deposits_count_d7::integer

             -- Make assumptions + Add to bi_db.v_daily_features
             --, campaign_max_payout::integer
             --, campaign_max_payout_per_ccv::float

        from bi_db.kronos_model_training
        where se_age_days>0 and
              deployment_start_date >= '2022-01-01'


[Data_Processing]
# outliers to be removed
outliers_to_be_removed = {'tutorials_d7': {'threshold': 1000, 'is_above': True}}

# create buckets of categorical features
features_to_bucket = {'most_played_game': 25,
                     'country': 10,
                     'language': 10}
# columns to drop
cols_to_drop = ['application_id', 'country', 'language', 'most_played_game']

# numeric features to convert to categorical
numeric_to_category = ['is_tipping_panel', 'is_bot_command_usage',
                       'is_overlay', 'is_website_visit', 'is_se_live',
                       'is_alert_box_fired', 'is_sesp_page_visit', 'is_open_stream_report']


# Choose 1 of the following options: YES or NO (split data to 3 parts (train, validation, test) OR 2 parts (train, test))
is_train_val_test = NO

# target column
target = 'tutorials_d7'

# ------------------------ IF pipeline == REGRESSOR - Define the following parameter: ------------------------ #
# Choose 1 of the following options: YES or NO (train only on a non-zero target data OR on all data)
train_only_on_non_zero_target_data = NO

# ------------------------ IF pipeline == CLASSIFIER+REGRESSOR - Define the following parameters:  ------------------------ #
# Probability threshold that filters classifier output (output passed as input to the regressor)
probability_threshold_that_filter_clf_output_passed_as_input_to_the_reg = 0.5
# Choose 1 of the 2 following options: YES or NO (train reg on clf's stratified data)
use_clf_split_data_to_keep_stratify_in_reg = NO


[Model_Parameters]
# Choose the following type: REGRESSOR
model_type = REGRESSOR

# model parameters
param = {"seed": 42,  # used to generate the folds
        "tree_method": "gpu_hist",  # speed up processing by using gpu power
        "n_estimators": 20000,  # number of trees
        "early_stopping_rounds":50  # overfitting prevention, stop early if no improvement in learning
        }

# Choose 1 of the following options: reg:tweedie / reg:gamma
objective = reg:tweedie

# W.R.T objective - Choose 1 of the following options: tweedie-nloglik@ / gamma-nloglik / rmse
eval_metric = tweedie-nloglik@

# W.R.T objective - Choose float from 1 to 2
tweedie_variance_power = 1.4
# W.R.T objective - Choose 1 of the following: D2TweedieScore / MeanTweedieScore
tweedie_loss_function = D2TweedieScore

# Choose 1 of the following options: YES or NO (irrelevant for regressor)
is_cross_validation = NO

# number of tuning trials
n_trials = 10000


[Scoring_Functions]
# Choose 1 of the following regression scoring functions: ['AveragePrecisionScore', 'LogLoss', 'RMSE', 'TweedieScore', 'GammaScore']
regressor_scoring_functions = ['TweedieScore']

# filters
r2_filter = 0


[GCS]
# ID of GCS bucket
bucket = acceptance-rate-prediction-streamelements-1337

# Folder path in GCS bucket
folder_path_of_model_file = kronos/training/


[Dataset]
# File name
filename = raid_tutorials_model_training_dataset

# Choose 1 of the following locations: LOCAL or REDSHIFT or GCS or GCS_VIA_LOCAL
location = REDSHIFT


[Locations]
# Choose 1 of the following locations: LOCAL or GCS or GCS_VIA_LOCAL
location_for_writing_model = GCS


[Pipeline]
# Pipeline name
pipeline_name = RAID_Tutorials

# Choose 1 of the following pipelines: REGRESSOR or CLASSIFIER+REGRESSOR
pipeline = CLASSIFIER+REGRESSOR